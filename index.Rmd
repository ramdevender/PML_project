# Coursera Practical Machine Learning - The Course Project


```{r}
set.seed(174)
library(ggplot2)
library(gridExtra)
library(doMC)
registerDoMC(cores = 4)
p <- 0.75
k <- 10
```


# Data processing

Raw daset has been loaded into `data.frame` and filtered in odrder to remove summary rows. 

```{r}
data <- read.csv('~/Workspace/coursera/practical_machine_learning/pml-training.csv', as.is=TRUE, na.strings=c('', NA))
data <- data[data$new_window == "no", ]
```

Resulting dataset contains `r dim(data)[1]` rows and `r dim(data)[2]` columns.

After loading `user_name` and `classe` column have been converted into `factor` variables. 

```{r}
data$classe <- factor(data$classe)
data$user_name <- factor(data$user_name)
```

Dataset has been splited into train and test dataset using `caret::createDataPartition` with `p` equal to `r p`.

```{r}
inTrain <- caret::createDataPartition(data$classe, p=p, list=FALSE)
training <- data[inTrain, ]
testing <- data[-inTrain, ]
```


Dataset contains large number of summary columns. Since summary rows have been removed those columns contain only `NA` values and are no longer relevant and can be removed.

```{r}

summary.columns <- round(apply(training, 2, function(x) {return(sum(is.na(x)/dim(training)[1]))}), 2) == 1.0
colnames(training)[summary.columns]
training <- training[, !summary.columns]
```

Several variables (like `num_window` or `cvtd_timestamp`) show clear functional relation with `classe` for each user. 

```{r}
ggplot(training, aes(x=user_name, y=num_window, colour=classe)) + geom_point()
```

These variables are clearly related to the data collection process and I decided not to use any of these (as well as the user id) for my model.

```{r}
numeric.features <- 8:60
dim(training)
training <- training[, numeric.features]
```

From the resulting dataset I removed highly correlated variables using `caret::findCorrelation` function.

```{r}
highly.corelated <- caret::findCorrelation(cor(training[, 1:52]), cutoff=0.8)
training <- training[, -highly.corelated]
```

As a result of described steps I reduced number of variables to `r dim(data)[2] - 1`.
Exploratory data analysis on the remaining data showed multiple class-based clusters. Based on clusters distribution I decided to use random forests.

```{r}
grid.arrange(
    ggplot(training, aes(x=accel_arm_z, y=yaw_belt, colour=classe)) + geom_point(),
    ggplot(training, aes(x=pitch_dumbbell, y=total_accel_belt, colour=classe)) + geom_point(),
    ggplot(training, aes(x=total_accel_arm, y=yaw_forearm, colour=classe)) + geom_point(),
    ggplot(training, aes(x=roll_arm, y=total_accel_forearm, colour=classe)) + geom_point(),
    ncol=2
)
```

# Cross-validation

To estimate out of sample error `r k`-fold cross validation has been used.

```{r cache=TRUE}
folds <- caret::createFolds(training$classe, k=k, list=TRUE, returnTrain=FALSE)
modelFits <- lapply(folds, function(fold) {
    return(
        list(
            modelFitRF = NA,
            predictionRF = NA,
            result = NA
        )
    )
})

for (i in 1:k) {
    
    fold <- folds[[i]]
    modelFitRF <- caret::train(
        classe ~ ., method='rf', data=training[-fold, ]
    )
    predictionRF <- predict(modelFitRF, training[fold, ])
    result <- caret::confusionMatrix(
        predictionRF, training[fold, ]$classe
    )
    modelFits[[i]] <- list(
        modelFitRF = modelFitRF,
        predictionRF = predictionRF,
        result = result
    )
}

mean.accuracy <- mean(sapply(modelFits, function(x) { return(x$result$overall[[1]]) }))
sd.accuracy <- sd(sapply(modelFits, function(x) { return(x$result$overall[[1]]) }))
sqrt.n <- sqrt(k)
se.accuracy <- sd.accuracy / sqrt.n
ci <- list(lower=round(mean.accuracy - se.accuracy * 1.96, 4), upper=round(mean.accuracy + se.accuracy * 1.96, 4))
```

Based on the results of the cross-validation step we can calculate 95% confidence interval for accuracy as (`r ci$lower`, `r ci$upper`).


# Final results

Best performing model has been applied to the testing and after that used for the final submission.

```{r}
modelFitRF <- modelFits[[which.max(sapply(modelFits, function(x) { return(x$result$overall[[1]]) }))]]$modelFitRF
predictionRF <- predict(modelFitRF, testing)
caret::confusionMatrix(predictionRF, testing$classe)
```


